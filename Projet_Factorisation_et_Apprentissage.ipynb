{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ypRpf9XU6hQ"
   },
   "source": [
    "# Enoncé du Projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0leEaW8UXl1-"
   },
   "source": [
    "* Il s'agit d'implémenter $5$ modèles pour un système de recommendation de films à partir des données Netflix. \n",
    "\n",
    "* Les modèles à implémenter sont présentés dans l'[article](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf) de Koren. Le dernier modèle de l'article est intitulé **Integrated Model**. Celui-ci a remporté le [Prix Netflix](https://en.wikipedia.org/wiki/Netflix_Prize) en $2008$. \n",
    "\n",
    "* Les données (téléchargeables à partir de ce [lien](https://archive.org/download/nf_prize_dataset.tar))  contiennent $100$ millions de notations (ratings) de $480 000$ utilisateurs sur $17 000$ films. Le but de chacun des modèles à implémenter consiste à **prédire** la notation d'un **utilisateur** donné sur l'ensemble des **films** que celui-ci n'a pas encore regardés. La recommendation pour cet utilisateur consiste à lui proposer la liste des films par ordre décroissant de notations prédites.\n",
    "\n",
    "* Chaque modèle est formulé comme une [Régression Linéaire](https://colab.research.google.com/drive/13tj_epwjFWkxBrcXwm0EELh0a81K1ID2#scrollTo=F075W1a2BWSe) dont les paramètres sont à estimer par procédure de [Gradient Descent](https://colab.research.google.com/drive/13tj_epwjFWkxBrcXwm0EELh0a81K1ID2#scrollTo=VqJhJGBduTXw). La performance de chaque modèle est évaluée par le critère RMSE (racine carrée de la Mean Squared Error vue dans le  [Chapitre Régression](https://colab.research.google.com/drive/13tj_epwjFWkxBrcXwm0EELh0a81K1ID2#scrollTo=X8iC5mkh3orV)).\n",
    "\n",
    "* Les modèles à implémenter sont:\n",
    "  1. Baseline Estimates décrit dans la section $2.1$ de l'article;\n",
    "  2. Correlation-Based Neighbourhood décrit par l'équation $(3)$ dans la section $2.2$;\n",
    "  3. Correlation-Based Neighbourhood with implicit data décrit par l'équation $(10)$ dans la section $3$;\n",
    "  4. SVD++ décrit par l'équation $(15)$ dans la section $4$;\n",
    "  5. Integrated Model décrit par l'équation $(16)$ dans la section $5$. \n",
    "\n",
    "* Dans la méthodologie ci-dessous, nous décrivons la façon d'organiser les données ainsi que les $5$ modèles à implémenter. Les notations de l'article ont été conservées afin de faciliter le basculement entre le notebook et l'article.\n",
    "\n",
    "* Le code final doit être livré en $6$ fichiers: le premier pour la compilation et des ensembles d'apprentissage et de tests; les $5$ pour chacun des modèles à implémenter. Dans le cas d'utilisation de librairies externes, mettre en commentaire la procédure d'installation de celle-ci dans chaque fichier où elle est utilisée.\n",
    "\n",
    "* Pour toute question ou incompréhension vous êtes invités à  m'écrire sur mon adresse mail: nedjmeddine.allab@gmail.com ou via  messagerie sur [linkedIn](https://www.linkedin.com/in/nedjmeddine-allab-phd-87201243/) pour des échanges plus rapides.\n",
    "\n",
    "* Bon courage.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uM8zENSoVBIk"
   },
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GD_HZMGg5DAn"
   },
   "source": [
    "## 1. Data Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfWy43BX5H0v"
   },
   "source": [
    "### 1.1. Generation of the rating dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2DJDaHK6L7T"
   },
   "source": [
    "* Write Python function **rating_compiler** to compile from the training_set.tar, the $17770$ files and store the result into one data structure named $\\bf{D}$;\n",
    "\n",
    "* $\\bf{D}$ can be a numpy matrix, csv file/pandas DataFrame, sparse matrix, hdf5 file...;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMCp614961Sp"
   },
   "source": [
    "### 1.2. Generation of training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxnaEdrW64Rn"
   },
   "source": [
    "* Extract from $\\bf{D}$ the ratings corresponding to the users and movies described in the qualifying.txt and store the result into one data structure named $\\bf{T}$;\n",
    "\n",
    "* Construct training dataset $\\bf{R}$ as $\\bf{D}$ from which we remove entries present in $\\bf{T}$;  \n",
    "\n",
    "* $\\bf{D}$, $\\bf{T}$ and $\\bf{R}$ must all have the same format (for example users as rows and films as columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVfSJT8rVKeN"
   },
   "source": [
    "## 2. Baseline Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWxQteGtVQwT"
   },
   "source": [
    "* Let $u$ and $v$ be two users and $i$ and $j$ two films;\n",
    "\n",
    "* we define:\n",
    "  *  $r_{ui}$ as the rating by user $u$ on film $i$;\n",
    "  *  $\\hat{r}_{ui}$ as the **predicted** rating of $r_{ui}$;\n",
    "\n",
    "\n",
    "* In Netflix data $99\\%$ of ratings are missing, the $(u,i)$ pairs for which $r_{ui}$ is known are stored in the set\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{K} = \\{(u,i) \\quad \\vert \\quad   r_{ui} \\quad \\mbox{is known}\\}.\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* In rating data, we tend to have users who systematically give higher ratings than others and also, some movies which receive higher ratings than others;\n",
    "\n",
    "* In Section 2.1 of the [article](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf) these tendencies are considered as baseline ratings $b_{ui}$ and are defined as\n",
    "\n",
    "\\begin{equation}\n",
    "b_{ui} = \\mu + b_u + b_i,\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* where:\n",
    "  *  $\\mu$ is the overall average rating;\n",
    "  * $b_u$ the observed deviation of user $u$;\n",
    "  * $b_i$ the observed deviation of movie $i$;\n",
    "\n",
    "\\\\\n",
    "\n",
    "\n",
    "\n",
    "* Estimates of $b_u$s and $b_i$s are obtained by the minimization of the regularized MSE loss function\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - b_{ui})^2 + \\lambda_1 \\left( \\sum_{u} b_u^2 + \\sum_{i} b_i^2 \\right),\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "  - where $\\lambda_1 \\left( \\sum_{u} b_u^2 + \\sum_{i} b_i^2 \\right)$ is the regularization term to avoid overfitting. The penality coefficient $\\lambda_1 = 0.02$.\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Write a python function **baseline_estimator** to estimate $b_u, b_i$ for every $(u,i) \\in \\mathcal{K}$;\n",
    "\n",
    "\\\\\n",
    "\n",
    "* The problem above can easily be transformed into linear regression problem and the minimization of the regularized MSE can be done through gradient descent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "om6y_3YlVRBJ"
   },
   "source": [
    "## 3. Neighbourhood Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUNMa40jagKf"
   },
   "source": [
    "### 3.1 Correlation-Based Neighbourhood Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9f-LnkbyVTLb"
   },
   "source": [
    "* To predict $r_{ui}$ neighbourhood approach look for a list of $k$ movies $\\{j_1,\\ldots,j_k \\}$ such that:\n",
    "  * the movies are already rated by $u$;\n",
    "  * the movies are appreciated by the same group of users suggesting their similarity with movie $i$;  \n",
    "\n",
    "* Similarity between movies $i$ and $j$ is defined as $s_{ij}$ and it is based on the pearson coefficient of correlation $\\rho_{ij}$   \n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "s_{ij} = \\frac{n_{ij}}{n_{ij} + \\lambda_2} \\rho_{ij},\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* where $n_{ij}$ is the number of users who rated both movies $i$ and $j$, $\\lambda_2$ is a regulation coefficient typically equal to $100$.\n",
    "\n",
    "\\\\\n",
    "\n",
    "* To predict $r_{ui}$:\n",
    "  * define the set $S^k (i;u)$ including the $k$ movies rated by $u$ and the most similar to $i$ according to $s_{ij}$;\n",
    "  * estimate $r_{ui}$ as the weighted sum of $r_{uj}$ such that\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + \\frac{1}{\\sum_{j \\in S^k (i;u)} s_{ij}} \\sum_{j \\in S^k (i;u)} s_{ij} (r_{uj} - b_{uj}).\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Write a Python function **correlation_based_neighbourhood_model** that estimate $r_{ui}$ according to the above equation. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hh7L9ncHa0CO"
   },
   "source": [
    "### Correlation-Based Neighbourhood Model with Implicit Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZeVHHE3a-4M"
   },
   "source": [
    "* In Section 2.5 of [article](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf), the author proposes to predict rating $r_{ui}$ from ***explicit*** neighbouring ratings $r_{uj}$ but also from ***implicit*** data such that: movie rental history or visited movies in the graphical interface;\n",
    "\n",
    "* Explicit and implicit data are formalized as follows: \n",
    "\n",
    "  * Let $u$ be a user associated with:\n",
    "    * $\\mbox{R}(u)$: set of movies for which ratings by $u$ are available;\n",
    "    * $\\mbox{N}(u)$: set of movies for which $u$ provided an implicit preference;\n",
    "\n",
    "* In the case of Netflix Data, implicit data is inferred from *which* movies have been rated. This implicitly tells us about preferences of the user;\n",
    "\n",
    "* Implicit feedback are derrived from ratings as binary matrix where:\n",
    "  * implicit preference of user $u$ to movie $i$ equals to 1 if $r_{ui}$ exists;\n",
    "  * implicit preference of user $u$ to movie $i$ equals to 0 if $r_{ui}$ does not exist;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0i4po3NlYnSH"
   },
   "source": [
    "* The new model will be developped from the the following prediction rule\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + \\sum_{j \\in \\mbox{R}(u)} (r_{uj} - b_{uj}) w_{ij},\n",
    "\\end{equation}\n",
    "\n",
    "* where $w_{ij}$ are associated to the similarity between movies $i$ and $j$.\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Note that here the author considers $(r_{uj} - b_{uj})$ as the weight to be applied on $w_{ij}$ such that:\n",
    "\n",
    "  * $w_{ij}$ is high if movies $i$ and $j$ are related and low otherwise;\n",
    "  * in case $w_{ij}$ is high and user $u$ rated $j$ higher than expected then $(r_{uj} - b_{uj})$ will be greater and thus the contribution of $w_{ij}$ will be significant;\n",
    "  * if however $w_{ij}$ is high but user $u$ rated $j$ just as expected leading to low  $(r_{uj} - b_{uj})$ the contribution of $w_{ij}$ will not be significant;\n",
    "  * This mecanism is interesting because it gives weight only to the movies $j$ related to $i$ that user $u$ really enjoyed. \n",
    "\n",
    "* Note also that in the equation above we consider **all** movies for which user $u$ has given an **explicit** rating;\n",
    "\n",
    "* To include **implicit** feedback the author adds to the equation above another weights $c_{ij}$  \n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + \\sum_{j \\in \\mbox{R}(u)} (r_{uj} - b_{uj}) w_{ij} + \\sum_{j \\in \\mbox{N}(u)} c_{ij},\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* where $c_{ij}$ is high if movie $j$ is related to $i$ and if user $u$ implicitly said that $j$ belongs to his category of films.\n",
    "\n",
    "\\\\\n",
    "\n",
    "* The author suggests to normalize the equation above by the suqared root of $\\mbox{R}(u)$ and $\\mbox{N}(u)$ sizes   \n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + \\frac{1}{\\sqrt{|\\mbox{R}(u)|}}\\sum_{j \\in \\mbox{R}(u)} (r_{uj} - b_{uj}) w_{ij} + \\frac{1}{\\sqrt{|\\mbox{N}(u)|}}\\sum_{j \\in \\mbox{N}(u)} c_{ij},\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* For a better computation efficiency, only the $k$ nearest movies will be selected from explicit and implicit sets and respectively stored in $\\mbox{R}^k (i;u)$ and $\\mbox{N}^k (i;u)$.\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Finally, the prediction rule is defined as follows\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + \\frac{1}{\\sqrt(|\\mbox{R}^k (i;u)|)}\\sum_{j \\in \\mbox{R}^k (i;u)} (r_{uj} - b_{uj}) w_{ij} + \\frac{1}{\\sqrt(|\\mbox{N}^k (i;u)|)}\\sum_{j \\in \\mbox{N}^k (i;u)} c_{ij}.\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* The $b_{uj}$ of the $4^{th}$ term are the baseline prediction estimated in your first function. In this new model they are considered as constants;\n",
    "\n",
    "* The parameters are: $b_u, b_i, w_{ij}, c_{ij}$ estimated by the minimization of the regularized MSE loss function\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda_4 \\left( \\sum_{u} b_u^2 + \\sum_{i} b_i^2  + \\sum_{j \\in \\mbox{R}^k (i;u)} w_{i,j}^2 + \\sum_{j \\in \\mbox{N}^k (i;u)} c_{i,j}^2 \\right).\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* The author suggests regularization coefficient $\\lambda_4 = 0.002$.\n",
    "\n",
    "* Write a Python function **correlation_based_implicit_neighbourhood_model** that estimate $r_{ui}$ according to the above equation. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOIvEO59VXwf"
   },
   "source": [
    "## 4. Latent Factor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LxA5wlLhYZY"
   },
   "source": [
    "#### Singular Value Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcuOCCboVaXA"
   },
   "source": [
    "* Latent factor models explain observed ratings as a dot product between two latent (or feature) vectors $p_u$ and $q_i$ both defined in  ${\\rm I\\!R}^f$;\n",
    "\n",
    "* In the context of recommender systems, $p_u$ may describe user $u$ in terms of his belonging to $f$ user categories while $q_i$, may represent for the movie $i$ the proportions of $f$ genres that it contains;\n",
    "\n",
    "* Singular Value Decomposition ([SVD](https://colab.research.google.com/drive/1xJHWm1LS39u4NDxnRsfjaxrux8HE1nbg#scrollTo=rgGYLnWH42aC)) of user-movie rating matrix is widely used and lead to the following prediction model  \n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + p_u^T q_i.\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* In practice, SVD raises difficulties due to the high portion of missing ratings ($99\\%$ in the Netflix Dataset), we tend to model only the observed ratings by minimizing the regularized MSE loss function\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda_3 \\left( \\sum_{u} b_u^2 + \\sum_{i} b_i^2  + ||p_u||^2 + ||q_i||^2 \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdRFoiQchpx6"
   },
   "source": [
    "### Improved Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM2mhkKthtmM"
   },
   "source": [
    "* **Patereck** proposes in his [article](https://www.cs.uic.edu/~liub/KDD-cup-2007/proceedings/Regular-Paterek.pdf) to model $p_u$ only on rated movies;\n",
    "\n",
    "* In that case, each movie $i$ becomes associated with **two** factors vectors $q_i$ and $x_i$ such that each user $u$ will be represented by the factor vector \n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "p_u = \\frac{1}{\\sqrt{ | \\mbox{R}(u) |}} \\sum_{j \\in \\mbox{R}(u)} x_j,\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* leading to the new prediction model\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + q_i^T \\frac{1}{\\sqrt{ | \\mbox{R}(u) |}} \\sum_{j \\in \\mbox{R}(u)} x_j.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GGaccjzqNGw"
   },
   "source": [
    "### Asymmetric SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNleAh2cqNYb"
   },
   "source": [
    "* Following the improved SVD paradigm, **Koren** came up with asymmetric SVD that includes implicit feedback;\n",
    "\n",
    "* Each movie $i$ is associated with $3$ factors vectors $q_i, x_i, y_i \\in {\\rm I\\!R}^f$ leading to the following prediction model\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + q_i^T \\left( \\frac{1}{\\sqrt{ | \\mbox{R}(u) |}} \\sum_{j \\in \\mbox{R}(u)} (r_{uj} - b_{uj}) x_j +  \\frac{1}{\\sqrt{ | \\mbox{N}(u) |}}\\sum_{j \\in \\mbox{N}(u)} y_j \\right).\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* This model presents many advantages such as:\n",
    "  * new users do not require retraining as it depends only on movies;\n",
    "  * recommendations can be explained in terms of movies only;\n",
    "  * it has less parameters when the number of users is larger than the number of films;\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Just like the other models, parameters are estimated through the minimization of regularized MSE loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ebKnxDPswSHw"
   },
   "source": [
    "### SVD++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Evm5cPdGwUqA"
   },
   "source": [
    "* **Koren** highlighted in Section 4 of his [article](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf) that introducing implicit feedback directly in the SVD prediction rule will yield better results\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = b_{ui} + q_i^T \\left( p_u  +  \\frac{1}{\\sqrt{ | \\mbox{N}(u) |}}\\sum_{j \\in \\mbox{N}(u)} y_j \\right).\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* Write a Python program named **SVD++** that estimate $r_{ui}$ according to the above equation. Estimation of parameters is done through the minimization of a regularized MSE Loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zB-4Vetz9RMz"
   },
   "source": [
    "## 5. Integrated Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPfId6tc9RYh"
   },
   "source": [
    "* Empiric research shows that Neighborhood\n",
    "and factor models do not capture same informations; \n",
    "\n",
    "* **Koren** ultimately proposed in Section 5 of his [article](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf) to combine between Latent and Neighbourhood models to enrich each other as \n",
    "\n",
    "\\\\\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + q_i^T \\left( p_u  +  \\frac{1}{\\sqrt{ | \\mbox{N}(u) |}}\\sum_{j \\in \\mbox{N}(u)} y_j \\right) + \\frac{1}{\\sqrt{|\\mbox{R}(u)|}}\\sum_{j \\in \\mbox{R}(u)} (r_{uj} - b_{uj}) w_{ij} + \\frac{1}{\\sqrt{|\\mbox{N}(u)|}}\\sum_{j \\in \\mbox{N}(u)} c_{ij}.\n",
    "\\end{equation}\n",
    "\n",
    "\\\\\n",
    "\n",
    "* First three terms describe general properties of the movie and the user;\n",
    "\n",
    "* Forth term provides the interaction between user's profile and  movie's profile;\n",
    "\n",
    "* Last two terms contributes fine grained adjustments that are hard to profile;\n",
    "\n",
    "* Write Python program named **integrated_model** that estimate $r_{ui}$ according to the above equation by minimizing regularized MSE Loss function."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GD_HZMGg5DAn",
    "DfWy43BX5H0v",
    "DMCp614961Sp",
    "FVfSJT8rVKeN",
    "om6y_3YlVRBJ",
    "TUNMa40jagKf",
    "sOIvEO59VXwf",
    "-LxA5wlLhYZY",
    "AdRFoiQchpx6",
    "4GGaccjzqNGw",
    "ebKnxDPswSHw",
    "zB-4Vetz9RMz"
   ],
   "name": "Projet Factorisation et Apprentissage.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
